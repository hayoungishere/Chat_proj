{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(sol)Problem_04(딥러닝).ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scb4NQe2zCPP"
      },
      "source": [
        "# **Digit 데이터를 이용한 <span style=\"color:darkgreen\">뉴럴네트워크</span> 문제**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyVZUOyPZlkN"
      },
      "source": [
        "> **<span style=\"color:red\">다음 문항을 풀기 전에 </span>아래 코드를 실행하시오.**<br>\n",
        "> 반드시 코드와 주석을 읽고 문제를 푸시오. <br>\n",
        "> 출력된 데이터 설명을 **반드시** 읽고 문제를 푸시오.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiSDKfH9abY7",
        "outputId": "36f0efde-15a9-47e4-fe48-c66284b23795"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "x = digits.images # 인풋으로 사용할 데이터.\n",
        "y = digits.target # 아웃풋으로 사용할 데이터.\n",
        "\n",
        "print(digits.DESCR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 5620\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "    Graduate Studies in Science and Engineering, Bogazici University.\n",
            "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "    Electrical and Electronic Engineering Nanyang Technological University.\n",
            "    2005.\n",
            "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "    Algorithm. NIPS. 2000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq9Hd0ukSxIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28d6ddf-ffda-44cb-872a-6d18c5a273aa"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 8, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJN4YuM-Sz6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b46d13e-9ffe-44be-80bf-20151aad7716"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjJw5R69TL7g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d4fec745-e9fb-4a80-fd0d-c12a63256192"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(x[100], cmap='gray')\n",
        "plt.show()\n",
        "print(y[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heKPp9gV0che"
      },
      "source": [
        "# Q1. 다음 조건에 맞추어 데이터를 분할하시오.\n",
        "---------------------------\n",
        "* 변수명 규칙 : x_train, x_test, y_train, y_test\n",
        "* train : test = 9 : 1\n",
        "* y의 클래스가 골고루 분할이 되도록 stratify하게 분할한다.\n",
        "* random state, seed등은 2021로 고정.\n",
        "---------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaW-TZha1QFX"
      },
      "source": [
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "\n",
        "x_train, x_test, y_train, y_test = tts(x, y, test_size = 0.1, stratify=y, random_state=2021)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS_lbVG5TsDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef16a9c8-57ea-406c-ab41-cb3e349fe721"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1617, 8, 8)\n",
            "(180, 8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oviV2HIh1ePP"
      },
      "source": [
        "# Q2. 모든 x들을 min-max scaling 하시오.\n",
        "---------------------------\n",
        "* 모든 트레이닝 규칙은 트레이닝 셋을 이용하여 찾아낸다.\n",
        "* 제대로 스케일링 되었는지, 결과도 확인한다.\n",
        "---------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk5q8Ema1ePR"
      },
      "source": [
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "max_ = x_train.max()\n",
        "min_ = x_train.min()\n",
        "\n",
        "x_train = ( x_train - min_ )/( max_ - min_ ) # pixel range 변화 : (0~16) -> (0~1)\n",
        "x_test =( x_test - min_ )/( max_ - min_ ) # pixel range 변화 : (0~16) -> (0~1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loxUUgb6UdzX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0fb82c-673c-4539-ea84-81c8a3f4fde8"
      },
      "source": [
        "print('pixel max : ', max_, 'pixel min : ', min_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel max :  1.0 pixel min :  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnpStAuj2Gmu"
      },
      "source": [
        "# Q3. 실행할 때마다 트레이닝셋의 이미지 하나를 랜덤하게 시각화 하는 코드를 작성하시오.\n",
        "--------------------\n",
        "* 그 이미지가 어떤 클래스인지도 같이 출력하는 코드를 작성하시오.\n",
        "----------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "q_24UYjO2aju",
        "outputId": "c7ec2112-cf74-4ae4-d0db-bebe3a16283c"
      },
      "source": [
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "id = np.random.randint(0, len(x_train))\n",
        "\n",
        "print(f\"아래 이미지는 {y_train[id]}입니다.\")\n",
        "plt.imshow(x_train[id], cmap='Greys')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아래 이미지는 1입니다.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tf9hpt_21LC"
      },
      "source": [
        "# Q4. y들을 원핫인코딩 하시오.\n",
        "----------------\n",
        "* 모든 전처리 규칙은 트레이닝셋을 이용하여 찾는다.\n",
        "--------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ujn3mJa3ISt"
      },
      "source": [
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_ca = len(set(y_train))\n",
        "\n",
        "y_train = to_categorical(y_train, num_ca)\n",
        "y_test = to_categorical(y_test, num_ca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjh5kd0MWM9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fd8885-8829-4607-989a-80bb32405535"
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNfKuylW4iuv"
      },
      "source": [
        "# Q5. 다음 조건에 맞추어 뉴럴넷을 모델링 하시오.\n",
        "------------------------------\n",
        "* model1 에 모델을 선언해둔다.\n",
        "* 컴파일까지 마친다.\n",
        "    - 모니터링용 지표로 accuracy를 둔다.\n",
        "* 모델 구조는 아래와 같다.\n",
        "    - x의 모양에 맞는 적절한 인풋레이어\n",
        "    - Fully connected layer로 연결하기 위한 모양변환 레이어 --> Flatten 쓰라는 말!\n",
        "    - Fully connected layer, 64개 노드, swish(activation)\n",
        "    - Fully connected layer, 64개 노드, swish(activation)\n",
        "    - 적절한 아웃풋 레이어 --> 분류할 클래스 개수에 맞는 Dense레이어를 구성해라!\n",
        "-----------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP5zJDHK5GT2",
        "outputId": "63ab4faa-7726-49bc-dc27-3e2d3177accd"
      },
      "source": [
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "keras.backend.clear_session()\n",
        "\n",
        "il = keras.layers.Input(shape=(8,8)) #input의 shape 정보, placeholder tensor\n",
        "hl = keras.layers.Flatten()(il) # (8,8) -> (64)로 vectorization\n",
        "hl = keras.layers.Dense(64, 'swish')(hl) # hidden layer 1\n",
        "hl = keras.layers.Dense(64, 'swish')(hl) # hidden layer 2\n",
        "ol = keras.layers.Dense(10, 'softmax')(hl) # output layer class 10개\n",
        "\n",
        "model1 = keras.models.Model(il, ol)\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 8, 8)]            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 8,970\n",
            "Trainable params: 8,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nBHkekK5lUF"
      },
      "source": [
        "# Q6. 다음 조건에 맞추어 model1을 얼리스토핑을 이용하여 학습시키시오.\n",
        "--------------\n",
        "* epochs = 10000 -> 학습데이터 전체를 몇 번 학습할 것인가?\n",
        "* batch size는 256 -> 1회 학습시 사용할 데이터의 수\n",
        "* 10번 연속 개선이 없으면 stop\n",
        "    - loss가 유지만 되어도 개선됨으로 간주\n",
        "* 얼리스토핑시, 가장 성능이 좋았던 가중치로 복구.\n",
        "* 벨리데이션 셋은, 트레이닝 셋의 15%를 사용.\n",
        "----------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzT6ssUq59GI",
        "outputId": "80d4d544-77c2-42b7-a572-8f4173f9bf6b"
      },
      "source": [
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   min_delta=0, # 개선의 기준이 0. validataion_loss가 0이상이면 개선되고 있다고 판단\n",
        "                   patience=10, # 몇 epoch 동안 개선이 없으면 학습을 정지할 것인가\n",
        "                   verbose=1, # 학습하면서 early stopping log를 출력할건지 여부\n",
        "                   restore_best_weights=True # early stopping 시 가장 좋은 가중치로 복구할 것인지 여부\n",
        "                   )\n",
        "\n",
        "model1.fit(x_train, y_train, epochs=10000, batch_size=256, validation_split=0.15, #validation_split -> 학습셋의 15%를 validation 데이터로 사용(나머지 85%는 학습셋으로 사용)\n",
        "           callbacks=[es], verbose=1) # callbacks : 사용할 callback 함수의 리스트 얼리 스타핑을 사용."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0328 - accuracy: 0.9964 - val_loss: 0.0940 - val_accuracy: 0.9630\n",
            "Epoch 2/10000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9949 - val_loss: 0.1058 - val_accuracy: 0.9588\n",
            "Epoch 3/10000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9956 - val_loss: 0.0919 - val_accuracy: 0.9671\n",
            "Epoch 4/10000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9956 - val_loss: 0.0966 - val_accuracy: 0.9588\n",
            "Epoch 5/10000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9956 - val_loss: 0.0947 - val_accuracy: 0.9588\n",
            "Epoch 6/10000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9971 - val_loss: 0.0938 - val_accuracy: 0.9588\n",
            "Epoch 7/10000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9964 - val_loss: 0.1036 - val_accuracy: 0.9588\n",
            "Epoch 8/10000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9949 - val_loss: 0.0926 - val_accuracy: 0.9671\n",
            "Epoch 9/10000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9964 - val_loss: 0.0965 - val_accuracy: 0.9588\n",
            "Epoch 10/10000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9978 - val_loss: 0.0946 - val_accuracy: 0.9588\n",
            "Epoch 11/10000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0262 - accuracy: 0.9971 - val_loss: 0.0943 - val_accuracy: 0.9588\n",
            "Epoch 12/10000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9971 - val_loss: 0.1011 - val_accuracy: 0.9547\n",
            "Epoch 13/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.0994 - val_accuracy: 0.9588\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00013: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f40ff12c310>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34VQNpKS6lsg"
      },
      "source": [
        "# Q7. 다음 조건에 맞추어 뉴럴넷을 모델링 하시오.\n",
        "------------------------------\n",
        "* model2 에 모델을 선언해둔다.\n",
        "* 컴파일까지 마친다.\n",
        "    - 모니터링용 지표로 accuracy를 둔다.\n",
        "* 모델 구조는 아래와 같다.\n",
        "    - x의 모양에 맞는 적절한 인풋레이어\n",
        "    - Fully connected layer로 연결하기 위한 모양변환 레이어\n",
        "    - Fully connected layer, 128개 노드, swish\n",
        "    - Batch normalization\n",
        "    - drop out : drop rate 25%\n",
        "    - Fully connected layer, 128개 노드, swish\n",
        "    - Batch normalization\n",
        "    - drop out : drop rate 25%\n",
        "    - 적절한 아웃풋 레이어\n",
        "-----------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anm52rbJ6lsg",
        "outputId": "7980d17f-1b29-4aff-e750-7fc3aa0ed63d"
      },
      "source": [
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "il = keras.layers.Input(shape=(8,8))\n",
        "hl = keras.layers.Flatten()(il)\n",
        "hl = keras.layers.Dense(128, 'swish')(hl) # 더 많은 퍼셉트론 사용 -> 성능개선 o but 과적합 우려\n",
        "hl = keras.layers.BatchNormalization()(hl) # 과적합을 줄여주는 레이어\n",
        "hl = keras.layers.Dropout(0.25)(hl) # 과적합을 줄여주는 레이어\n",
        "hl = keras.layers.Dense(128, 'swish')(hl) # 더 많은 퍼센트론 사용 -> 성능개선 o but 과적합 우려\n",
        "hl = keras.layers.BatchNormalization()(hl) # 과적합을 줄여주는 레이어\n",
        "hl = keras.layers.Dropout(0.25)(hl) # 과적합을 줄여주는 레이어\n",
        "ol = keras.layers.Dense(10, 'softmax')(hl)\n",
        "\n",
        "model2 = keras.models.Model(il, ol)\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 8, 8)]            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 27,146\n",
            "Trainable params: 26,634\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXoVesOe8cuR"
      },
      "source": [
        "# Q8. 다음 조건에 맞추어 model2을 얼리스토핑을 이용하여 학습시키시오.\n",
        "--------------\n",
        "* epochs = 10000\n",
        "* batch size는 256\n",
        "* 10번 연속 개선이 없으면 stop\n",
        "    - loss가 유지만 되어도 개선됨으로 간주\n",
        "* 얼리스토핑시, 가장 성능이 좋았던 가중치로 복구.\n",
        "* 벨리데이션 셋은, 트레이닝 셋의 15%를 사용.\n",
        "----------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkLRUsyV8cuT",
        "outputId": "282a7ee5-726c-451a-850a-21a630c0c2b4"
      },
      "source": [
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   min_delta=0, patience=10,\n",
        "                   verbose=1, restore_best_weights=True)\n",
        "\n",
        "model2.fit(x_train, y_train, epochs=10000, batch_size=256, validation_split=0.15,\n",
        "           callbacks=[es], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "6/6 [==============================] - 1s 49ms/step - loss: 2.3918 - accuracy: 0.2438 - val_loss: 2.1624 - val_accuracy: 0.2099\n",
            "Epoch 2/10000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2048 - accuracy: 0.6063 - val_loss: 2.0423 - val_accuracy: 0.4897\n",
            "Epoch 3/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6791 - accuracy: 0.7831 - val_loss: 1.9482 - val_accuracy: 0.6831\n",
            "Epoch 4/10000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4617 - accuracy: 0.8639 - val_loss: 1.8766 - val_accuracy: 0.6996\n",
            "Epoch 5/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3677 - accuracy: 0.8959 - val_loss: 1.8180 - val_accuracy: 0.6955\n",
            "Epoch 6/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3125 - accuracy: 0.9076 - val_loss: 1.7682 - val_accuracy: 0.6996\n",
            "Epoch 7/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2717 - accuracy: 0.9272 - val_loss: 1.7236 - val_accuracy: 0.7119\n",
            "Epoch 8/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2377 - accuracy: 0.9316 - val_loss: 1.6800 - val_accuracy: 0.7202\n",
            "Epoch 9/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2087 - accuracy: 0.9410 - val_loss: 1.6361 - val_accuracy: 0.7284\n",
            "Epoch 10/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1970 - accuracy: 0.9410 - val_loss: 1.5945 - val_accuracy: 0.7449\n",
            "Epoch 11/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1768 - accuracy: 0.9541 - val_loss: 1.5530 - val_accuracy: 0.7449\n",
            "Epoch 12/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1658 - accuracy: 0.9534 - val_loss: 1.5111 - val_accuracy: 0.7654\n",
            "Epoch 13/10000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1677 - accuracy: 0.9585 - val_loss: 1.4693 - val_accuracy: 0.7819\n",
            "Epoch 14/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1384 - accuracy: 0.9672 - val_loss: 1.4283 - val_accuracy: 0.8107\n",
            "Epoch 15/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1383 - accuracy: 0.9658 - val_loss: 1.3868 - val_accuracy: 0.8189\n",
            "Epoch 16/10000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1336 - accuracy: 0.9651 - val_loss: 1.3469 - val_accuracy: 0.8272\n",
            "Epoch 17/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1313 - accuracy: 0.9672 - val_loss: 1.3022 - val_accuracy: 0.8395\n",
            "Epoch 18/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1210 - accuracy: 0.9694 - val_loss: 1.2560 - val_accuracy: 0.8395\n",
            "Epoch 19/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1118 - accuracy: 0.9723 - val_loss: 1.2136 - val_accuracy: 0.8395\n",
            "Epoch 20/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1074 - accuracy: 0.9716 - val_loss: 1.1706 - val_accuracy: 0.8477\n",
            "Epoch 21/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1073 - accuracy: 0.9680 - val_loss: 1.1294 - val_accuracy: 0.8642\n",
            "Epoch 22/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0959 - accuracy: 0.9811 - val_loss: 1.0872 - val_accuracy: 0.8683\n",
            "Epoch 23/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0979 - accuracy: 0.9767 - val_loss: 1.0413 - val_accuracy: 0.8683\n",
            "Epoch 24/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0931 - accuracy: 0.9803 - val_loss: 0.9963 - val_accuracy: 0.8930\n",
            "Epoch 25/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0882 - accuracy: 0.9811 - val_loss: 0.9509 - val_accuracy: 0.9053\n",
            "Epoch 26/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0860 - accuracy: 0.9767 - val_loss: 0.9099 - val_accuracy: 0.9218\n",
            "Epoch 27/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0857 - accuracy: 0.9731 - val_loss: 0.8706 - val_accuracy: 0.9259\n",
            "Epoch 28/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0778 - accuracy: 0.9789 - val_loss: 0.8319 - val_accuracy: 0.9300\n",
            "Epoch 29/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0688 - accuracy: 0.9854 - val_loss: 0.7914 - val_accuracy: 0.9342\n",
            "Epoch 30/10000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0736 - accuracy: 0.9862 - val_loss: 0.7539 - val_accuracy: 0.9342\n",
            "Epoch 31/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0733 - accuracy: 0.9818 - val_loss: 0.7161 - val_accuracy: 0.9383\n",
            "Epoch 32/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9753 - val_loss: 0.6799 - val_accuracy: 0.9424\n",
            "Epoch 33/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0631 - accuracy: 0.9876 - val_loss: 0.6412 - val_accuracy: 0.9424\n",
            "Epoch 34/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0659 - accuracy: 0.9862 - val_loss: 0.6044 - val_accuracy: 0.9424\n",
            "Epoch 35/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0548 - accuracy: 0.9920 - val_loss: 0.5687 - val_accuracy: 0.9465\n",
            "Epoch 36/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0584 - accuracy: 0.9905 - val_loss: 0.5361 - val_accuracy: 0.9506\n",
            "Epoch 37/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0611 - accuracy: 0.9803 - val_loss: 0.5075 - val_accuracy: 0.9547\n",
            "Epoch 38/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0581 - accuracy: 0.9862 - val_loss: 0.4797 - val_accuracy: 0.9588\n",
            "Epoch 39/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0596 - accuracy: 0.9898 - val_loss: 0.4510 - val_accuracy: 0.9547\n",
            "Epoch 40/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 0.9891 - val_loss: 0.4256 - val_accuracy: 0.9547\n",
            "Epoch 41/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0499 - accuracy: 0.9884 - val_loss: 0.4003 - val_accuracy: 0.9588\n",
            "Epoch 42/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0472 - accuracy: 0.9884 - val_loss: 0.3733 - val_accuracy: 0.9588\n",
            "Epoch 43/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0488 - accuracy: 0.9898 - val_loss: 0.3457 - val_accuracy: 0.9588\n",
            "Epoch 44/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 0.9913 - val_loss: 0.3221 - val_accuracy: 0.9588\n",
            "Epoch 45/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0517 - accuracy: 0.9898 - val_loss: 0.3020 - val_accuracy: 0.9588\n",
            "Epoch 46/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 0.9964 - val_loss: 0.2847 - val_accuracy: 0.9630\n",
            "Epoch 47/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0446 - accuracy: 0.9905 - val_loss: 0.2686 - val_accuracy: 0.9588\n",
            "Epoch 48/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0433 - accuracy: 0.9905 - val_loss: 0.2537 - val_accuracy: 0.9588\n",
            "Epoch 49/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0514 - accuracy: 0.9862 - val_loss: 0.2400 - val_accuracy: 0.9588\n",
            "Epoch 50/10000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0369 - accuracy: 0.9942 - val_loss: 0.2262 - val_accuracy: 0.9630\n",
            "Epoch 51/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0439 - accuracy: 0.9898 - val_loss: 0.2116 - val_accuracy: 0.9671\n",
            "Epoch 52/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0410 - accuracy: 0.9884 - val_loss: 0.1984 - val_accuracy: 0.9671\n",
            "Epoch 53/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 0.9927 - val_loss: 0.1859 - val_accuracy: 0.9671\n",
            "Epoch 54/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9942 - val_loss: 0.1752 - val_accuracy: 0.9671\n",
            "Epoch 55/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0320 - accuracy: 0.9956 - val_loss: 0.1650 - val_accuracy: 0.9671\n",
            "Epoch 56/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 0.9934 - val_loss: 0.1560 - val_accuracy: 0.9712\n",
            "Epoch 57/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0345 - accuracy: 0.9942 - val_loss: 0.1478 - val_accuracy: 0.9671\n",
            "Epoch 58/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0372 - accuracy: 0.9934 - val_loss: 0.1406 - val_accuracy: 0.9671\n",
            "Epoch 59/10000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0353 - accuracy: 0.9942 - val_loss: 0.1336 - val_accuracy: 0.9712\n",
            "Epoch 60/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9905 - val_loss: 0.1262 - val_accuracy: 0.9712\n",
            "Epoch 61/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9891 - val_loss: 0.1212 - val_accuracy: 0.9753\n",
            "Epoch 62/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0346 - accuracy: 0.9934 - val_loss: 0.1169 - val_accuracy: 0.9753\n",
            "Epoch 63/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9956 - val_loss: 0.1126 - val_accuracy: 0.9753\n",
            "Epoch 64/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 0.9964 - val_loss: 0.1080 - val_accuracy: 0.9753\n",
            "Epoch 65/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9971 - val_loss: 0.1046 - val_accuracy: 0.9712\n",
            "Epoch 66/10000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9949 - val_loss: 0.1013 - val_accuracy: 0.9712\n",
            "Epoch 67/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 0.9956 - val_loss: 0.0977 - val_accuracy: 0.9712\n",
            "Epoch 68/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0328 - accuracy: 0.9920 - val_loss: 0.0948 - val_accuracy: 0.9712\n",
            "Epoch 69/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0292 - accuracy: 0.9942 - val_loss: 0.0923 - val_accuracy: 0.9712\n",
            "Epoch 70/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0293 - accuracy: 0.9964 - val_loss: 0.0882 - val_accuracy: 0.9712\n",
            "Epoch 71/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9956 - val_loss: 0.0838 - val_accuracy: 0.9712\n",
            "Epoch 72/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9964 - val_loss: 0.0804 - val_accuracy: 0.9712\n",
            "Epoch 73/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0343 - accuracy: 0.9920 - val_loss: 0.0788 - val_accuracy: 0.9712\n",
            "Epoch 74/10000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9971 - val_loss: 0.0775 - val_accuracy: 0.9712\n",
            "Epoch 75/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9971 - val_loss: 0.0752 - val_accuracy: 0.9712\n",
            "Epoch 76/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9964 - val_loss: 0.0741 - val_accuracy: 0.9712\n",
            "Epoch 77/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9964 - val_loss: 0.0741 - val_accuracy: 0.9712\n",
            "Epoch 78/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0288 - accuracy: 0.9920 - val_loss: 0.0742 - val_accuracy: 0.9712\n",
            "Epoch 79/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9971 - val_loss: 0.0729 - val_accuracy: 0.9712\n",
            "Epoch 80/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9964 - val_loss: 0.0712 - val_accuracy: 0.9712\n",
            "Epoch 81/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9949 - val_loss: 0.0691 - val_accuracy: 0.9712\n",
            "Epoch 82/10000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9993 - val_loss: 0.0660 - val_accuracy: 0.9712\n",
            "Epoch 83/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 0.9942 - val_loss: 0.0645 - val_accuracy: 0.9712\n",
            "Epoch 84/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0189 - accuracy: 0.9978 - val_loss: 0.0645 - val_accuracy: 0.9753\n",
            "Epoch 85/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9971 - val_loss: 0.0641 - val_accuracy: 0.9753\n",
            "Epoch 86/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 0.9949 - val_loss: 0.0642 - val_accuracy: 0.9753\n",
            "Epoch 87/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9964 - val_loss: 0.0627 - val_accuracy: 0.9753\n",
            "Epoch 88/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9949 - val_loss: 0.0597 - val_accuracy: 0.9753\n",
            "Epoch 89/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9978 - val_loss: 0.0593 - val_accuracy: 0.9794\n",
            "Epoch 90/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9971 - val_loss: 0.0599 - val_accuracy: 0.9794\n",
            "Epoch 91/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 0.0603 - val_accuracy: 0.9794\n",
            "Epoch 92/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9964 - val_loss: 0.0608 - val_accuracy: 0.9794\n",
            "Epoch 93/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9949 - val_loss: 0.0611 - val_accuracy: 0.9794\n",
            "Epoch 94/10000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9964 - val_loss: 0.0619 - val_accuracy: 0.9794\n",
            "Epoch 95/10000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9971 - val_loss: 0.0623 - val_accuracy: 0.9794\n",
            "Epoch 96/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 0.9978 - val_loss: 0.0632 - val_accuracy: 0.9794\n",
            "Epoch 97/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0184 - accuracy: 0.9964 - val_loss: 0.0620 - val_accuracy: 0.9835\n",
            "Epoch 98/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0197 - accuracy: 0.9956 - val_loss: 0.0617 - val_accuracy: 0.9835\n",
            "Epoch 99/10000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 0.9985 - val_loss: 0.0610 - val_accuracy: 0.9835\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00099: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4102936090>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFGc2QHe8kfH"
      },
      "source": [
        "# Q9. 테스트셋 위에서 두 모델을 비교하시오.\n",
        "---------------------------------\n",
        "* 두 모델의 accuracy를 출력한다.\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_jhJafb8qGW",
        "outputId": "711e3b92-7dfa-4b9b-c5a6-dd4954ac7c86"
      },
      "source": [
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "model1.evaluate(x_test, y_test), model2.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.9833\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.10667146742343903, 0.9833333492279053],\n",
              " [0.0863223522901535, 0.9777777791023254])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH0Ru9Ey9E5k"
      },
      "source": [
        "# Q10. 성능이 더 좋은 모델을 이용해, 테스트 이미지를 시각화 하시오.\n",
        "----------------------------\n",
        "* 랜덤하게 테스트 이미지 한장을 시각화 한다.\n",
        "* 그 이미지가 실제 어떤 클래스인지 출력한다.\n",
        "    - 원핫 인코딩 된 정보를 출력하지 않는다.\n",
        "* 모델이 예측한 클래스도 같이 출력한다.\n",
        "    - 확률 정보를 출력하지 않는다.\n",
        "-----------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_ONJOesl9VOo",
        "outputId": "037b69d6-a7b9-40d3-9a1b-abe7645fe7d5"
      },
      "source": [
        "####################\n",
        "## your code here ##\n",
        "####################\n",
        "\n",
        "id = id = np.random.randint(0, len(x_test))\n",
        "\n",
        "y_pred = model2.predict(x_test[id:id+1])\n",
        "\n",
        "print(f\"아래 이미지는 : {y_test[id].argmax()} 입니다.\")\n",
        "print(f\"모델의 예측은 : {y_pred.argmax()} 입니다.\")\n",
        "plt.imshow(x_test[id], cmap='Greys')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아래 이미지는 : 8 입니다.\n",
            "모델의 예측은 : 8 입니다.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}